{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./results\\4_4_11h_19m_44s\\1\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\2\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\3\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\4\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\5\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\6\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\7\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\8\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\9\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\10\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\11\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\12\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\13\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\14\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\15\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\16\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\17\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\18\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\19\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\20\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\21\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\22\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\23\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\24\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\25\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\26\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\27\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\28\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\29\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\30\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\31\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\32\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\33\n",
      "Capture\n",
      "./results\\4_4_11h_19m_44s\\34\n",
      "Capture\n"
     ]
    }
   ],
   "source": [
    "## License: Apache 2.0. See LICENSE file in root directory.\n",
    "## Copyright(c) 2015-2017 Intel Corporation. All Rights Reserved.\n",
    "\n",
    "###############################################\n",
    "##      Open CV and Numpy integration        ##\n",
    "###############################################\n",
    "\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def stream(pipeline, fas_model=None, th=220, alpha=0.03, SAVE_DIR='./results'):\n",
    "    \n",
    "    now = datetime.now()\n",
    "    SAVE_DIR = os.path.join(SAVE_DIR, f'{now.month}_{now.day}_{now.hour}h_{now.minute}m_{now.second}s')\n",
    "    if not os.path.exists(SAVE_DIR):\n",
    "        os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "    \n",
    "    \"\"\"\n",
    "        ** Description **\n",
    "        Output rgb image and depth image in real time\n",
    "        \n",
    "        ** Args **\n",
    "        pipline     : stream pipeline\n",
    "        fas_model   : Face-Anit Spoofing Model\n",
    "        th          : Thresholding parameter, adjusting the acceptance distance for detph images\n",
    "        alpha       : Depth image scaling parameter, adjusts the degree of differentiation according to depth\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    i = 0\n",
    "    j = 0\n",
    "    pred = 0\n",
    "    TEXT = ['SUCCESS', 'FAIL']\n",
    "    COLORS = [(215, 145, 25), (25, 25, 215)]\n",
    "    \n",
    "    while True:    \n",
    "                \n",
    "        # -------------------------------------------\n",
    "        # Getting raw depth and rgb image\n",
    "        # -------------------------------------------\n",
    "        \n",
    "        # Wait for a coherent pair of frames: depth and color\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        depth_frame = frames.get_depth_frame()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        if not depth_frame or not color_frame:\n",
    "            continue\n",
    "        \n",
    "        # Convert images to numpy arrays\n",
    "        depth_image = np.asanyarray(depth_frame.get_data())\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "        # -------------------------------------------\n",
    "        # Post-processing\n",
    "        # -------------------------------------------\n",
    "        \n",
    "        # cv2.convertScaleAbs(depth_image, alpha=alpha): return gray image of range [0, 255]\n",
    "        depth_scaled = cv2.convertScaleAbs(depth_image, alpha=alpha)\n",
    "        depth_scaled[depth_scaled != 0] = 255 - depth_scaled[depth_scaled != 0]\n",
    "        \n",
    "        # histogram equlization\n",
    "        depth_equal = cv2.equalizeHist(depth_scaled)\n",
    "        \n",
    "        # cv2.cvtColor: for visualization, convert 1-d image to 3-d image\n",
    "        depth_colormap = cv2.cvtColor(depth_equal, cv2.COLOR_GRAY2BGR)\n",
    "                \n",
    "        if fas_model is not None:\n",
    "            # output: spoof label\n",
    "            pred = 1\n",
    "        \n",
    "        # -------------------------------------------\n",
    "        # Postprocessing using thresholding\n",
    "        # -------------------------------------------\n",
    "        # depth_colormap[depth_equal > th] = 0.\n",
    "        \n",
    "        \n",
    "        H, W, _ = np.shape(color_image)\n",
    "        \n",
    "        # ROI\n",
    "        cv2.rectangle(color_image, (W//2-91, H//2-91), (W//2+91, H//2+91), (71, 134, 0), 1)\n",
    "        \n",
    "        if fas_model is not None:\n",
    "            # PAD result\n",
    "            cv2.rectangle(color_image, (0, 0), (145, 40), COLORS[pred], -1)\n",
    "            cv2.putText(color_image, TEXT[pred], (5,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "        \n",
    "        depth_colormap_dim = depth_colormap.shape\n",
    "        color_colormap_dim = color_image.shape\n",
    "\n",
    "        # If depth and color resolutions are different, resize color image to match depth image for display\n",
    "        if depth_colormap_dim != color_colormap_dim:\n",
    "            resized_color_image = cv2.resize(color_image, dsize=(depth_colormap_dim[1], depth_colormap_dim[0]), interpolation=cv2.INTER_AREA)\n",
    "            images = np.hstack((resized_color_image, depth_colormap))\n",
    "        else:\n",
    "            images = np.hstack((color_image, depth_colormap))\n",
    "\n",
    "        # Show images\n",
    "        # To quick, press 'q' key\n",
    "        # To save, press 'space bar'\n",
    "        cv2.namedWindow('RealSense', cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow('RealSense', images)\n",
    "        if cv2.waitKey(1)  == ord('q'):\n",
    "            break\n",
    "        elif cv2.waitKey(1)  == 32:\n",
    "            \n",
    "            i += 1\n",
    "            \n",
    "            save_dir = os.path.join(SAVE_DIR, str(i))\n",
    "            print(save_dir)\n",
    "            if not os.path.exists(save_dir):\n",
    "                os.makedirs(save_dir, exist_ok=True)\n",
    "            \n",
    "            \n",
    "            # concat = np.concatenate([color_image, depth_colormap], axis=-1)\n",
    "            concat = np.concatenate([color_image, depth_colormap], axis=-1)\n",
    "            concat_crop = concat[H//2-90:H//2+90, W//2-90:W//2+90]\n",
    "            \n",
    "            cv2.imwrite(os.path.join(save_dir, f'{i}_full.png'), images)\n",
    "            cv2.imwrite(os.path.join(save_dir, f'{i}_crop_rgb.png'), concat_crop[:,:,:3])\n",
    "            cv2.imwrite(os.path.join(save_dir, f'{i}_crop_depth.png'), concat_crop[:,:,3:])\n",
    "            \n",
    "            # del concat, concat_crop\n",
    "            \n",
    "            ### check effectiveness of processing \n",
    "            depth_base = cv2.cvtColor(depth_scaled, cv2.COLOR_GRAY2BGR)\n",
    "            depth_hist = cv2.cvtColor(depth_equal, cv2.COLOR_GRAY2BGR)\n",
    "            cv2.rectangle(depth_hist, (0, 0), (W, H), (255, 0, 0), 4)\n",
    "            concat_depths = np.hstack([depth_base, depth_hist])\n",
    "            cv2.imwrite(os.path.join(save_dir, f'{j}_concat_depths.png'), concat_depths)\n",
    "            \n",
    "            concat_crop = np.hstack([concat_crop[:,:,:3], concat_crop[:,:,3:]])\n",
    "            concat_ = np.hstack([concat[:,:,:3], concat[:,:,3:]])\n",
    "            concat_resize = cv2.resize(concat_, dsize=(360, (480*360)//1280))\n",
    "            overall = np.vstack([concat_resize, concat_crop])\n",
    "            \n",
    "            \n",
    "            cv2.imwrite(os.path.join(save_dir, f'{j}_overall_results.png'), overall)\n",
    "            \n",
    "            del concat, concat_crop\n",
    "            del overall, concat_resize, concat_\n",
    "            del depth_base, depth_hist, concat_depths\n",
    "            \n",
    "            print('Capture')\n",
    "\n",
    "    \n",
    "def main():\n",
    "    # Configure depth and color streams\n",
    "    pipeline = rs.pipeline()\n",
    "    config = rs.config()\n",
    "\n",
    "    # Get device product line for setting a supporting resolution\n",
    "    pipeline_wrapper = rs.pipeline_wrapper(pipeline)\n",
    "    pipeline_profile = config.resolve(pipeline_wrapper)\n",
    "    device = pipeline_profile.get_device()\n",
    "    device_product_line = str(device.get_info(rs.camera_info.product_line))\n",
    "\n",
    "    found_rgb = False\n",
    "    for s in device.sensors:\n",
    "        if s.get_info(rs.camera_info.name) == 'RGB Camera':\n",
    "            found_rgb = True\n",
    "            break\n",
    "    if not found_rgb:\n",
    "        print(\"The demo requires Depth camera with Color sensor\")\n",
    "        exit(0)\n",
    "\n",
    "    config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "\n",
    "    if device_product_line == 'L500':\n",
    "        config.enable_stream(rs.stream.color, 960, 540, rs.format.bgr8, 30)\n",
    "    else:\n",
    "        config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "\n",
    "    # Start streaming\n",
    "    pipeline.start(config)\n",
    "\n",
    "    try:\n",
    "        # -------------------------\n",
    "        # Main function\n",
    "        # -------------------------\n",
    "        stream(pipeline=pipeline)    \n",
    "        exit()\n",
    "        \n",
    "    finally:\n",
    "        # Stop streaming\n",
    "        pipeline.stop()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42a931b84b80e88af4c8a8867d06f51dec7d74ddcf164e058a2caaca54f9426f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('real')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
